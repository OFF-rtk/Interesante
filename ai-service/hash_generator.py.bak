#!/usr/bin/env python3
import sys
import json
import numpy as np
from PIL import Image
import imagehash
import cv2
from scipy.fft import dct
import tensorflow as tf
import tensorflow_hub as hub

class HashGenerator:
    def __init__(self):
        # Load TensorFlow Hub model for feature extraction
        try:
            # Using MobileNetV2 for semantic features (lighter than CLIP)
            self.feature_extractor = hub.load("https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5")
            self.tf_available = True
            print("TensorFlow feature extractor loaded successfully", file=sys.stderr)
        except Exception as e:
            print(f"TensorFlow model unavailable: {e}", file=sys.stderr)
            self.tf_available = False
    
    def generate_phash(self, image_path):
        """Generate perceptual hash using imagehash library"""
        try:
            with Image.open(image_path) as img:
                # Convert to grayscale and resize for consistency
                img = img.convert('L').resize((32, 32), Image.Resampling.LANCZOS)
                phash = imagehash.phash(img, hash_size=16)
                return str(phash)
        except Exception as e:
            raise Exception(f"pHash generation failed: {e}")
    
    def generate_dct_hash(self, image_path):
        """Generate DCT-based hash for robust similarity detection"""
        try:
            with Image.open(image_path) as img:
                # Convert to grayscale
                img_gray = img.convert('L').resize((64, 64), Image.Resampling.LANCZOS)
                img_array = np.array(img_gray, dtype=np.float32)
                
                # Apply DCT transform
                dct_coeffs = dct(dct(img_array.T, norm='ortho').T, norm='ortho')
                
                # Keep only low-frequency coefficients (8x8 top-left)
                low_freq = dct_coeffs[:8, :8]
                
                # Generate binary hash based on median
                median = np.median(low_freq)
                binary_hash = low_freq > median
                
                # Convert to hex string
                hash_string = ""
                for i in range(0, 64, 8):
                    byte_val = 0
                    for j in range(8):
                        if i + j < 64:
                            bit_index = i + j
                            row, col = bit_index // 8, bit_index % 8
                            if binary_hash[row, col]:
                                byte_val |= (1 << (7 - j))
                    hash_string += f"{byte_val:02x}"
                
                return hash_string
        except Exception as e:
            raise Exception(f"DCT hash generation failed: {e}")
    
    def generate_tf_embedding(self, image_path):
        """Generate TensorFlow semantic embedding using MobileNetV2"""
        if not self.tf_available:
            return None
        
        try:
            with Image.open(image_path) as img:
                # Resize image to 224x224 (MobileNetV2 input size)
                img_resized = img.convert('RGB').resize((224, 224), Image.Resampling.LANCZOS)
                img_array = np.array(img_resized, dtype=np.float32)
                
                # Normalize to [0, 1] range
                img_array = img_array / 255.0
                
                # Add batch dimension
                img_batch = np.expand_dims(img_array, axis=0)
                
                # Convert to TensorFlow tensor
                img_tensor = tf.convert_to_tensor(img_batch)
                
                # Generate embedding
                features = self.feature_extractor(img_tensor)
                
                # Convert to list for JSON serialization
                embedding = features.numpy().squeeze().tolist()
                return embedding
        except Exception as e:
            print(f"TensorFlow embedding failed: {e}", file=sys.stderr)
            return None
    
    def generate_advanced_features(self, image_path):
        """Generate comprehensive feature set for image"""
        try:
            # Load image with OpenCV for additional features
            img_cv = cv2.imread(image_path)
            if img_cv is None:
                raise Exception("Could not load image with OpenCV")
            
            img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            
            # Calculate additional features
            features = {
                "brightness": float(np.mean(img_gray)),
                "contrast": float(np.std(img_gray)),
                "complexity": self.calculate_complexity(img_gray),
                "dominant_colors": self.get_dominant_colors(img_cv),
                "edge_density": self.calculate_edge_density(img_gray),
                "texture_energy": self.calculate_texture_energy(img_gray)
            }
            
            return features
        except Exception as e:
            print(f"Advanced features failed: {e}", file=sys.stderr)
            return None
    
    def calculate_complexity(self, img_gray):
        """Calculate image complexity using gradient magnitude"""
        try:
            grad_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)
            magnitude = np.sqrt(grad_x**2 + grad_y**2)
            return float(np.mean(magnitude))
        except:
            return 0.0
    
    def calculate_edge_density(self, img_gray):
        """Calculate edge density using Canny edge detection"""
        try:
            edges = cv2.Canny(img_gray, 50, 150)
            return float(np.sum(edges > 0) / edges.size)
        except:
            return 0.0
    
    def calculate_texture_energy(self, img_gray):
        """Calculate texture energy using Gabor filters"""
        try:
            # Create Gabor filter
            kernel = cv2.getGaborKernel((21, 21), 8, 0, 10, 0.5, 0, ktype=cv2.CV_32F)
            filtered = cv2.filter2D(img_gray, cv2.CV_8UC3, kernel)
            return float(np.var(filtered))
        except:
            return 0.0
    
    def get_dominant_colors(self, img_bgr, k=3):
        """Get dominant colors using k-means clustering"""
        try:
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            img_resized = cv2.resize(img_rgb, (64, 64))
            pixels = img_resized.reshape(-1, 3).astype(np.float32)
            
            # K-means clustering
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
            _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
            
            # Convert centers to list of RGB values
            dominant_colors = centers.astype(int).tolist()
            return dominant_colors
        except:
            return [[128, 128, 128]]  # Default gray

    def generate_all_features(self, image_path):
        return {
            "phash": self.generate_phash(image_path),
            "dct_hash": self.generate_dct_hash(image_path),
            "tf_embedding": self.generate_tf_embedding(image_path),
            "advanced_features": self.generate_advanced_features(image_path),
            "success": True
        }
def main():
    if len(sys.argv) != 2:
        print("Usage: python3 advanced_hash_tf.py <image_path>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    try:
        hash_generator = HashGenerator()
        
        # Generate all hash types and features
        result = {
            "phash": hash_generator.generate_phash(image_path),
            "dct_hash": hash_generator.generate_dct_hash(image_path),
            "tf_embedding": hash_generator.generate_tf_embedding(image_path),
            "advanced_features": hash_generator.generate_advanced_features(image_path),
            "success": True
        }
        
        # Output as JSON for easy parsing in Node.js
        print(json.dumps(result))
        
    except Exception as e:
        error_result = {
            "error": str(e),
            "success": False
        }
        print(json.dumps(error_result))
        sys.exit(1)

if __name__ == "__main__":
    main()
